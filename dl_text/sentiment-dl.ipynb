{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-25T11:26:30.003708Z","iopub.execute_input":"2021-11-25T11:26:30.004142Z","iopub.status.idle":"2021-11-25T11:26:30.028894Z","shell.execute_reply.started":"2021-11-25T11:26:30.004067Z","shell.execute_reply":"2021-11-25T11:26:30.028221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_table('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:18.429566Z","iopub.execute_input":"2021-11-23T13:02:18.42994Z","iopub.status.idle":"2021-11-23T13:02:18.723325Z","shell.execute_reply.started":"2021-11-23T13:02:18.429893Z","shell.execute_reply":"2021-11-23T13:02:18.722352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_table('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip')\ntest","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:18.72652Z","iopub.execute_input":"2021-11-23T13:02:18.726815Z","iopub.status.idle":"2021-11-23T13:02:18.853035Z","shell.execute_reply.started":"2021-11-23T13:02:18.726766Z","shell.execute_reply":"2021-11-23T13:02:18.851909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train,test])\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:18.856519Z","iopub.execute_input":"2021-11-23T13:02:18.856951Z","iopub.status.idle":"2021-11-23T13:02:18.888892Z","shell.execute_reply.started":"2021-11-23T13:02:18.856903Z","shell.execute_reply":"2021-11-23T13:02:18.887811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data.iloc[0,2]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:18.891007Z","iopub.execute_input":"2021-11-23T13:02:18.891521Z","iopub.status.idle":"2021-11-23T13:02:18.9006Z","shell.execute_reply.started":"2021-11-23T13:02:18.891466Z","shell.execute_reply":"2021-11-23T13:02:18.899138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\ntk = Tokenizer()\ntk.fit_on_texts(all_data['Phrase'])\ntk.word_index","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:18.902615Z","iopub.execute_input":"2021-11-23T13:02:18.903871Z","iopub.status.idle":"2021-11-23T13:02:26.800374Z","shell.execute_reply.started":"2021-11-23T13:02:18.903823Z","shell.execute_reply":"2021-11-23T13:02:26.799143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = tk.texts_to_sequences(all_data['Phrase'])\nprint(text[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:26.801979Z","iopub.execute_input":"2021-11-23T13:02:26.802554Z","iopub.status.idle":"2021-11-23T13:02:30.304909Z","shell.execute_reply.started":"2021-11-23T13:02:26.802499Z","shell.execute_reply":"2021-11-23T13:02:30.30367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(text).apply(len)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:30.307033Z","iopub.execute_input":"2021-11-23T13:02:30.307685Z","iopub.status.idle":"2021-11-23T13:02:30.600223Z","shell.execute_reply.started":"2021-11-23T13:02:30.30762Z","shell.execute_reply":"2021-11-23T13:02:30.599111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.distplot(pd.Series(text).apply(len))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:30.602224Z","iopub.execute_input":"2021-11-23T13:02:30.60249Z","iopub.status.idle":"2021-11-23T13:02:33.025126Z","shell.execute_reply.started":"2021-11-23T13:02:30.602452Z","shell.execute_reply":"2021-11-23T13:02:33.024085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 문장길이 통일(padding)\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\npad_text = pad_sequences(text,maxlen=30)\npad_text.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:33.029188Z","iopub.execute_input":"2021-11-23T13:02:33.029495Z","iopub.status.idle":"2021-11-23T13:02:34.815385Z","shell.execute_reply.started":"2021-11-23T13:02:33.029463Z","shell.execute_reply":"2021-11-23T13:02:34.814405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2 = pad_text[:len(train)]\ntest_2 = pad_text[len(train):]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:34.818968Z","iopub.execute_input":"2021-11-23T13:02:34.819359Z","iopub.status.idle":"2021-11-23T13:02:34.827494Z","shell.execute_reply.started":"2021-11-23T13:02:34.819325Z","shell.execute_reply":"2021-11-23T13:02:34.823275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_embedding(path):\n    embeddings = {}\n    with open(path) as f:\n        for line in f:\n            values = line.rstrip().split()  # rstrip() --> 맨 오른쪽 띄어쓰기를 없애주기 위함\n            word = values[0]   # word 에 영단어 할당\n            vector = np.asarray(values[1:],dtype=np.float32)   \n            # ram 터지는것 방지(array쓰면 RAM 소모량 감소) \n            # vector 숫자에 있는 64비트 float을 32비트 float으로 바꿔서 메모리 소모량 감소시킴\n            \n            embeddings[word] = vector\n    return embeddings\n\nembeddings = load_embedding('/kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:02:34.828956Z","iopub.execute_input":"2021-11-23T13:02:34.829261Z","iopub.status.idle":"2021-11-23T13:06:42.536563Z","shell.execute_reply.started":"2021-11-23T13:02:34.829179Z","shell.execute_reply":"2021-11-23T13:06:42.535293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_embedding(embeddings,word_index,vocab_size,dim):\n    embedding_matrix = np.zeros([vocab_size,dim])  # 우리 데이터셋의 단어크기에 맞는 행렬생성\n    for word,i in word_index.items():\n        vector = embeddings.get(word)   # get 함수 실행 : 단어가 없어도 출력값이 none으로 나오게 됨\n        if vector is not None:     # vector가 NaN이 아닐때\n            embedding_matrix[i] = vector\n    return embedding_matrix\n\nembedding_matrix = filter_embedding(embeddings,tk.word_index,len(tk.word_index)+1,300) \n# 300차원 --> 크롤링 파일이 300차원\nprint(embedding_matrix[1])   # the의 embedding","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:06:42.538797Z","iopub.execute_input":"2021-11-23T13:06:42.539141Z","iopub.status.idle":"2021-11-23T13:06:42.624947Z","shell.execute_reply.started":"2021-11-23T13:06:42.539093Z","shell.execute_reply":"2021-11-23T13:06:42.623795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 겹치는 단어 체크\nlen(set(tk.word_index) - set(embeddings))\n# set(tk.word_index) - set(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:06:42.627385Z","iopub.execute_input":"2021-11-23T13:06:42.627841Z","iopub.status.idle":"2021-11-23T13:06:42.951489Z","shell.execute_reply.started":"2021-11-23T13:06:42.627793Z","shell.execute_reply":"2021-11-23T13:06:42.950267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import *\nfrom tensorflow.keras.layers import *\nmodel = Sequential()\nmodel.add(Embedding(len(tk.word_index)+1,300,input_length=30,weights=[embedding_matrix],\n                   trainable=False))   \n# 300 --> embedding_matrix의 300차원\n# weights=[embedding_matrix] --> 학습할 단어들\n# trainable = False --> 이미 Embedding 들어가 있는데 굳이 재학습할 필요 X\n#model.add(Flatten())\nmodel.add(SpatialDropout1D(0.25))\n# Dropout --> Embedding층 직후 실행\n# SpatialDropout : 학습시 특정단어(감정관련 형용사)가 없어도 잘 예측할수 있게끔 도움\nmodel.add(Bidirectional(LSTM(32,return_sequences=True)))\n# return_sequences = True 좀더 sequences 안의 단어들을 더 잘 기억/이해하도록 재학습하는 옵션\n# 각 단어마다 한 차원이 출력되어 파라미터수가 늘어남\n# 재학습을 위한 차원 하나가 더 늘어남 \nmodel.add(Flatten())\n# --> model.add(Flatten())으로 차원을 늘려줌\nmodel.add(Dense(32,activation='relu'))  # Dense층 추가\nmodel.add(Dense(5,activation='softmax'))\nmodel.compile(metrics=['acc'],loss='sparse_categorical_crossentropy',optimizer='adam')\n# sparse --> 숫자일때 회귀라고 인식안하게(분류라고 인식하게)\nmodel.fit(train_2,train['Sentiment'],epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:06:42.953739Z","iopub.execute_input":"2021-11-23T13:06:42.954085Z","iopub.status.idle":"2021-11-23T13:14:27.864455Z","shell.execute_reply.started":"2021-11-23T13:06:42.954026Z","shell.execute_reply":"2021-11-23T13:14:27.863237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2 = Sequential()\nmodel_2.add(Embedding(len(tk.word_index)+1,300,input_length=30,weights=[embedding_matrix],\n                   trainable=False))   \nmodel_2.add(SpatialDropout1D(0.25))\nmodel_2.add(Bidirectional(GRU(32,return_sequences=True)))\nmodel_2.add(Flatten())\nmodel_2.add(Dense(32,activation='relu'))  \nmodel_2.add(Dense(5,activation='softmax'))\nmodel_2.compile(metrics=['acc'],loss='sparse_categorical_crossentropy',optimizer='adam')\nmodel_2.fit(train_2,train['Sentiment'],epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:14:27.866604Z","iopub.execute_input":"2021-11-23T13:14:27.867049Z","iopub.status.idle":"2021-11-23T13:21:54.32937Z","shell.execute_reply.started":"2021-11-23T13:14:27.86699Z","shell.execute_reply":"2021-11-23T13:21:54.32834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensemble\nresult_1 = model.predict(test_2)\nresult_2 = model_2.predict(test_2)\n\nresult = result_1 * 0.5 + result_2 * 0.5","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:21:54.331742Z","iopub.execute_input":"2021-11-23T13:21:54.332132Z","iopub.status.idle":"2021-11-23T13:22:09.862706Z","shell.execute_reply.started":"2021-11-23T13:21:54.332087Z","shell.execute_reply":"2021-11-23T13:22:09.861773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv')\n# test의 Phrase가 train에 동일하게 있다면 모델의 result에서 틀린값을 train 정답으로 정정하는 꼼수\n#result_class = result.argmax(1)\nresult_class = result.argmax(1)\nmapping = {phrase:sentiment for _,_,phrase,sentiment in train.values}\n# mapping\n\nfor i,phrase in enumerate(test['Phrase']):\n    if phrase in mapping:\n        result_class[i] = mapping[phrase]   ","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:23:56.471157Z","iopub.execute_input":"2021-11-23T13:23:56.47185Z","iopub.status.idle":"2021-11-23T13:23:56.83508Z","shell.execute_reply.started":"2021-11-23T13:23:56.471814Z","shell.execute_reply":"2021-11-23T13:23:56.834006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['Sentiment'] = result_class\nsub.to_csv('result.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:24:16.3841Z","iopub.execute_input":"2021-11-23T13:24:16.384691Z","iopub.status.idle":"2021-11-23T13:24:16.513992Z","shell.execute_reply.started":"2021-11-23T13:24:16.384653Z","shell.execute_reply":"2021-11-23T13:24:16.512886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 추가로 GRU를 써서 앙상블 하거나 K-fold 과정 추가하기!","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:32:53.09707Z","iopub.execute_input":"2021-11-23T12:32:53.097369Z","iopub.status.idle":"2021-11-23T12:32:53.10354Z","shell.execute_reply.started":"2021-11-23T12:32:53.097326Z","shell.execute_reply":"2021-11-23T12:32:53.102123Z"},"trusted":true},"execution_count":null,"outputs":[]}]}